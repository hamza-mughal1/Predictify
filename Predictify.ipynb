{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Created by Hamza Mughal\n",
        "\n",
        "some of the examples model generated\n",
        "\n",
        "(input before hyphen - output afte hyphen)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "I am a - I am a humble man who is here to learn from my friends in the new world\n",
        "\n",
        "you dont - you dont know what its like to carry a child and give birth\n",
        "\n",
        "he - he made small talk\n",
        "\n",
        "his - his body was discovered in an abandoned theater\n",
        "\n",
        "her - her room was empty and the bed was still neatly made for her\n",
        "\n",
        "I am sorry - I am sorry but we have to ask you to be out by the end of the week\n",
        "\n",
        "I apologize - I apologize for interrupting like this\n",
        "\n",
        "do - do you know what time it is\n",
        "\n",
        "you know that - you know that its a bad thing for me\n",
        "\n",
        "fine - fine ill do it my dear man\n",
        "\n",
        "how to - how to find out this thing you dont know\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4iFhrI7RvBEH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKKj_dQTqXdX"
      },
      "source": [
        "# Load dataset. Kaggle 'movie-subtitle-dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NedwWeRJWOS2",
        "outputId": "4253527d-8f1a-4032-a5e8-756f86b71150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/adiamaan/movie-subtitle-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 243M/243M [00:01<00:00, 209MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"adiamaan/movie-subtitle-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh4ULNFmf6V7"
      },
      "outputs": [],
      "source": [
        "file_path = path + \"/movies_subtitles.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGrlkXywfKIf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read only 'text' column and 50k records only (to avoid memory hit)\n",
        "df = pd.read_csv(file_path, usecols=['text'],nrows=50000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing"
      ],
      "metadata": {
        "id": "f137iLSPw9gz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "btE__S6Xg_bw"
      },
      "outputs": [],
      "source": [
        "# remove unecessory characters\n",
        "df['text'] = df['text'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
        "df['text'] = df['text'].str.replace(r'<.*?>', '', regex=True)\n",
        "df['text'] = df['text'].str.replace(r'\\n', ' ', regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing data"
      ],
      "metadata": {
        "id": "t5gwT1dTxJJZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DIi_Ai3xjCly",
        "outputId": "377e7529-ae0d-4ebb-e9f8-84612441237a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "# Breaking sentences/phrases into sequences using nltk E.g. \"this is a sentence\" -> [\"this\",\"is\",\"a\",\"sentence\"]\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Download the 'punkt_tab' data package\n",
        "\n",
        "# Ensure the 'text' column contains only strings\n",
        "df['text'] = df['text'].astype(str)\n",
        "\n",
        "df['sequence'] = df['text'].apply(word_tokenize)\n",
        "df = df['sequence']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Craete input and output sequences"
      ],
      "metadata": {
        "id": "QQpszJksx2FA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VliBggvIjRXR"
      },
      "outputs": [],
      "source": [
        "# create sequences E.g.\n",
        "# column (sequence)\n",
        "# [\"this\",\"is\",\"a\",\"sentence\"]\n",
        "# ->\n",
        "# column (sequence)     column (output)\n",
        "# [\"this\",\"is\",\"a\"]     [\"sentence\"]\n",
        "# [\"this\",\"is\"]         [\"a\"]\n",
        "# [\"this\"]              [\"is\"]\n",
        "\n",
        "def process_sequences(df):\n",
        "    \"\"\"\n",
        "    Processes sequences to create input-output pairs for language modeling.\n",
        "\n",
        "    This function takes a DataFrame where each row contains a sequence of tokens\n",
        "    (e.g., words in a sentence) and transforms it into a new DataFrame suitable\n",
        "    for training a language model.\n",
        "\n",
        "    For each sequence in the input DataFrame, it creates multiple input-output pairs.\n",
        "    The input is a subsequence of the original sequence, and the output is the\n",
        "    next word in the original sequence.\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): A DataFrame where each row contains a sequence of tokens.\n",
        "                                 It is assumed that the sequences are stored in a column\n",
        "                                 named 'sequence'.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A new DataFrame with two columns: 'sequence' and 'output'.\n",
        "                           Each row represents an input-output pair for the language model.\n",
        "    \"\"\"\n",
        "    new_rows = []  # Initialize an empty list to store the new rows\n",
        "    for sequence in df:  # Iterate through each sequence in the input DataFrame\n",
        "        for i in range(1, len(sequence)):  # Iterate through different lengths of subsequences\n",
        "            new_rows.append({  # Create a new row for each subsequence\n",
        "                'sequence': sequence[:-i],  # Input: Subsequence from the beginning to (len - i)\n",
        "                'output': sequence[-i]     # Output: The next word in the original sequence\n",
        "            })\n",
        "    return pd.DataFrame(new_rows)  # Convert the list of new rows into a DataFrame\n",
        "\n",
        "# Processed dataframe\n",
        "result_df = process_sequences(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyJNHRGkodX-"
      },
      "outputs": [],
      "source": [
        "# convert pandas sequence into datafram\n",
        "df = df.to_frame(name='sequence')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "collapsed": true,
        "id": "-B9q9_dHvyLJ",
        "outputId": "60d09168-99c2-423d-abe3-b8e00e6d4a62"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b4bb0fe2-544c-48c0-9304-ca7afaeb9d85\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[BOY, All, right, everyone, This, is, a]</td>\n",
              "      <td>stickup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[BOY, All, right, everyone, This, is]</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[BOY, All, right, everyone, This]</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[BOY, All, right, everyone]</td>\n",
              "      <td>This</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[BOY, All, right]</td>\n",
              "      <td>everyone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239002</th>\n",
              "      <td>[Starting, now, Ill, never, compose]</td>\n",
              "      <td>another</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239003</th>\n",
              "      <td>[Starting, now, Ill, never]</td>\n",
              "      <td>compose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239004</th>\n",
              "      <td>[Starting, now, Ill]</td>\n",
              "      <td>never</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239005</th>\n",
              "      <td>[Starting, now]</td>\n",
              "      <td>Ill</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239006</th>\n",
              "      <td>[Starting]</td>\n",
              "      <td>now</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>239007 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4bb0fe2-544c-48c0-9304-ca7afaeb9d85')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b4bb0fe2-544c-48c0-9304-ca7afaeb9d85 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b4bb0fe2-544c-48c0-9304-ca7afaeb9d85');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ca25123c-455d-4f09-b005-a0eeb6747b5c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca25123c-455d-4f09-b005-a0eeb6747b5c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ca25123c-455d-4f09-b005-a0eeb6747b5c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7093ab9b-7f62-43d2-85a1-3b1421b0dc86\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7093ab9b-7f62-43d2-85a1-3b1421b0dc86 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                        sequence    output\n",
              "0       [BOY, All, right, everyone, This, is, a]   stickup\n",
              "1          [BOY, All, right, everyone, This, is]         a\n",
              "2              [BOY, All, right, everyone, This]        is\n",
              "3                    [BOY, All, right, everyone]      This\n",
              "4                              [BOY, All, right]  everyone\n",
              "...                                          ...       ...\n",
              "239002      [Starting, now, Ill, never, compose]   another\n",
              "239003               [Starting, now, Ill, never]   compose\n",
              "239004                      [Starting, now, Ill]     never\n",
              "239005                           [Starting, now]       Ill\n",
              "239006                                [Starting]       now\n",
              "\n",
              "[239007 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create tokenizer/dictionary of your dataset"
      ],
      "metadata": {
        "id": "1LoZXi94y2FH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3o7WTgmem3IN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Initialize the Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Fit the tokenizer on your corpus (i.e., all the text in your dataset)\n",
        "tokenizer.fit_on_texts(df[\"sequence\"])\n",
        "del df\n",
        "\n",
        "# # Convert the text sequences to integer sequences\n",
        "input_sequences = tokenizer.texts_to_sequences(result_df['sequence'])\n",
        "output_words = tokenizer.texts_to_sequences(result_df['output'])\n",
        "del result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHcZmqEOtrNT"
      },
      "outputs": [],
      "source": [
        "# flatting output sequence\n",
        "output_words = [item[0] for item in output_words]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add padding to input sequence to make all input sequence same lenght, to allow parallel training"
      ],
      "metadata": {
        "id": "L1UXnzzbzDHy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8uJwhpoqLUP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Determine the maximum sequence length\n",
        "max_sequence_length = max(len(seq) for seq in input_sequences)\n",
        "\n",
        "# Pad the input sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
        "del input_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create one-hot encoding of your output sequence to allow model to do probablilty distribution using softmax"
      ],
      "metadata": {
        "id": "dg2pz57XzRXS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSeStB_GtY_l"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Number of unique tokens in your vocabulary\n",
        "vocab_size = len(tokenizer.word_index) + 1  # +1 because tokenizer indices are 1-based\n",
        "\n",
        "# Convert to one-hot encoded format\n",
        "output_words_categorical = to_categorical(output_words, num_classes=vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlE9BK_dV5Wq"
      },
      "source": [
        "# GLOVE embeddings if want to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Nn13SBwlV51S",
        "outputId": "423f6571-188d-4782-f4cf-3acd2502fdcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-01-22 14:34:37--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n",
            "--2025-01-22 14:34:37--  https://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877800501 (1.7G) [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip.1’\n",
            "\n",
            "glove.42B.300d.zip.   2%[                    ]  52.63M  5.12MB/s    eta 3m 28s ^C\n",
            "Archive:  glove.42B.300d.zip\n",
            "  inflating: glove.42B.300d.txt      "
          ]
        }
      ],
      "source": [
        "# download and unzip embeddings\n",
        "!wget https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
        "!unzip glove.42B.300d.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_matrix(vocab_size, tokenizer, embedding_dim):\n",
        "  \"\"\"\n",
        "  Creates an embedding matrix using pre-trained GloVe embeddings.\n",
        "\n",
        "  Args:\n",
        "      vocab_size (int): The size of the vocabulary.\n",
        "      tokenizer (keras.preprocessing.text.Tokenizer): The tokenizer used to create the vocabulary.\n",
        "      embedding_dim (int): The dimensionality of the GloVe embeddings.\n",
        "\n",
        "  Returns:\n",
        "      numpy.ndarray: The embedding matrix.\n",
        "  \"\"\"\n",
        "  vocabulary = tokenizer.word_index.keys()  # Get all the words in the vocabulary\n",
        "  path_to_embeddings = '/content/glove.42B.300d.txt'  # Path to the GloVe embeddings file\n",
        "\n",
        "  # Load GloVe embeddings into a dictionary, where keys are words and values are embedding vectors\n",
        "  embeddings_index = {}\n",
        "  with open(path_to_embeddings, encoding='utf-8') as f:\n",
        "      for line in f:\n",
        "          values = line.split()  # Split the line into word and embedding values\n",
        "          word = values[0]  # The first value is the word\n",
        "          if word in vocabulary:  # Only consider words that are in our vocabulary\n",
        "            coefs = np.asarray(values[1:], dtype='float32')  # Convert embedding values to a NumPy array\n",
        "            embeddings_index[word] = coefs  # Store the embedding vector for the word\n",
        "\n",
        "  # Create the embedding matrix\n",
        "  embedding_matrix = np.zeros((vocab_size, embedding_dim))  # Initialize with zeros\n",
        "  for word, i in tokenizer.word_index.items():  # Iterate through the vocabulary\n",
        "      embedding_vector = embeddings_index.get(word)  # Get the embedding vector for the word\n",
        "      if embedding_vector is not None:  # If an embedding vector was found for the word\n",
        "          embedding_matrix[i] = embedding_vector  # Store it in the embedding matrix\n",
        "\n",
        "  return embedding_matrix  # Return the created embedding matrix"
      ],
      "metadata": {
        "id": "KPTjcmu4smQw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create model"
      ],
      "metadata": {
        "id": "5qUueDWk0MGF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "collapsed": true,
        "id": "GlDsqtJlt7cl",
        "outputId": "615d0c8c-fbf3-4828-fd46-44d7b769c9c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,618,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │       \u001b[38;5;34m2,618,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,618,400</span> (9.99 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,618,400\u001b[0m (9.99 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,618,400</span> (9.99 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,618,400\u001b[0m (9.99 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Set up model parameters\n",
        "vocab_size = len(tokenizer.word_index) + 1  # +1 for padding token\n",
        "hidden_units = 512  # Number of units in the LSTM layer\n",
        "embedding_dim = 300  # Match the GloVe dimension, if using\n",
        "use_glove_embeddings = False\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "\n",
        "if use_glove_embeddings:\n",
        "  embedding_matrix = create_embedding_matrix(tokenizer, embedding_dim)\n",
        "  # 1. Embedding layer: Convert token IDs to dense vectors\n",
        "  model.add(Embedding(\n",
        "      input_dim=vocab_size,\n",
        "      output_dim=embedding_dim,\n",
        "      weights=[embedding_matrix],\n",
        "      trainable=True  # Set to False to keep GloVe embeddings fixed\n",
        "  ))\n",
        "else:\n",
        "  # 1. Embedding layer: Convert token IDs to dense vectors\n",
        "  model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "\n",
        "# 2. LSTM layer: Capture sequential dependencies\n",
        "model.add(LSTM(units=hidden_units))\n",
        "\n",
        "# 3. Dense layer: Output a distribution over possible next words\n",
        "model.add(Dense(vocab_size, activation='softmax'))  # Softmax to generate a probability distribution\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summarize the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "604iMNGwqKH8"
      },
      "outputs": [],
      "source": [
        "del output_words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "NqcacIh80X4n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uX0sOPvTaCRK",
        "outputId": "69f1db8c-6548-47b2-cd52-9a36864ece99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 13ms/step - accuracy: 0.0744 - loss: 6.5237\n",
            "Epoch 2/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 13ms/step - accuracy: 0.1530 - loss: 5.1098\n",
            "Epoch 3/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 14ms/step - accuracy: 0.2145 - loss: 4.1865\n",
            "Epoch 4/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 13ms/step - accuracy: 0.3282 - loss: 3.2543\n",
            "Epoch 5/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - accuracy: 0.4581 - loss: 2.5246\n",
            "Epoch 6/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - accuracy: 0.5635 - loss: 2.0018\n",
            "Epoch 7/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - accuracy: 0.6447 - loss: 1.6220\n",
            "Epoch 8/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - accuracy: 0.6963 - loss: 1.3800\n",
            "Epoch 9/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.7299 - loss: 1.2244\n",
            "Epoch 10/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.7503 - loss: 1.1225\n",
            "Epoch 11/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - accuracy: 0.7636 - loss: 1.0563\n",
            "Epoch 12/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.7669 - loss: 1.0234\n",
            "Epoch 13/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.7696 - loss: 1.0046\n",
            "Epoch 14/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.7763 - loss: 0.9697\n",
            "Epoch 15/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - accuracy: 0.7739 - loss: 0.9650\n",
            "Epoch 16/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - accuracy: 0.7761 - loss: 0.9467\n",
            "Epoch 17/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 13ms/step - accuracy: 0.7743 - loss: 0.9473\n",
            "Epoch 18/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - accuracy: 0.7788 - loss: 0.9319\n",
            "Epoch 19/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - accuracy: 0.7783 - loss: 0.9242\n",
            "Epoch 20/20\n",
            "\u001b[1m2649/2649\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step - accuracy: 0.7784 - loss: 0.9135\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f2b75d81890>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(padded_input_sequences, output_words_categorical, epochs=15, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model"
      ],
      "metadata": {
        "id": "3_E5xOlw0ep4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61qXUAh4sd5p"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# save model\n",
        "with open('predictify-model.pkl', 'wb') as f:\n",
        "    pickle.dump({'model': model, 'tokenizer': tokenizer}, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use model to generate text"
      ],
      "metadata": {
        "id": "60OkZyxb0g4A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NuPG3ssZuqAF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_sentence(input_sequence, model, tokenizer, num_words=10):\n",
        "    \"\"\"\n",
        "    Generates a sentence by predicting the next words based on a given starting sequence.\n",
        "\n",
        "    Args:\n",
        "        input_sequence (list): The starting sequence of words.\n",
        "        model: The trained language model.\n",
        "        tokenizer: The tokenizer used to process the text.\n",
        "        num_words (int): The number of additional words to generate.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated sentence.\n",
        "    \"\"\"\n",
        "\n",
        "    input_sequence = input_sequence.split()\n",
        "\n",
        "    # Ensure input_sequence is a list\n",
        "    if not isinstance(input_sequence, list):\n",
        "        input_sequence = [input_sequence]\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        input_sequence_tokenized = tokenizer.texts_to_sequences([input_sequence])\n",
        "        input_sequence_tokenized = np.array(input_sequence_tokenized[0])\n",
        "        input_sequence_tokenized = input_sequence_tokenized.reshape(1, -1)\n",
        "\n",
        "        predicted_probabilities = model.predict(input_sequence_tokenized)\n",
        "        predicted_word_index = predicted_probabilities.argmax(axis=-1)\n",
        "        predicted_word = tokenizer.index_word[predicted_word_index[0]]\n",
        "\n",
        "        input_sequence.append(predicted_word)\n",
        "\n",
        "    return \" \".join(input_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the pre-trained model and tokenizer from the  pickle file\n",
        "with open('predictify-model.pkl', 'rb') as f:\n",
        "    loaded_data = pickle.load(f)\n",
        "    model = loaded_data['model']\n",
        "    tokenizer = loaded_data['tokenizer']"
      ],
      "metadata": {
        "id": "vOB4Lq6X1NqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qtG-EGXKvNGA"
      },
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "sentence = generate_sentence(\"enter your prompt\", model, tokenizer, num_words=15)\n",
        "print(sentence)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}